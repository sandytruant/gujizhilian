# 古籍智联gujizhilian

古籍智联（暂时取了个很土的名字，大家可以想想这个工具叫什么）是一款中文输入法插件（待开发），目标是能够根据输入的部分拼音直接联想出可能的对应古籍中的完整语句，以解决当下主流输入法输入古籍中语句效率低下的问题。

## 任务分解

### 1. 语料库准备

- 收集古代典籍（暂时只针对**先秦到两汉的经典文学库**），并将其整理为结构化的数据（目标形式待定，可以用**Elasticsearch**）。

  - Elasticsearch：https://www.elastic.co/elasticsearch
  - 古籍资料网站：https://ctext.org/zh

- 文本-音节映射：为了能够通过拼音查询到典籍中的句子，需要给语料库添加拼音标注。

  - 可能的实现工具：Python中的pypinyin库。
  - 例子：

  ```Python
  from pypinyin import pinyin, lazy_pinyin
  
  text = "你好，世界"
  pinyin_seq = ' '.join(lazy_pinyin(text))  # 生成拼音序列
  print(pinyin_seq)  # 输出: ni hao ， shi jie
  ```

- 分词（**可能需要**）：将一段连续的文本拆分成一个个有意义的词语或者短语。
  - 分词工具：
    - https://github.com/jiaeyan/Jiayan（专用于古汉语的分词工具）
    - https://github.com/fxsjy/jieba（最常用的中文分词工具，但不一定适用于古汉语）

### 2. 查询匹配算法（后端开发）

- **精准匹配：**查询哪些古籍语句直接包含所输入的拼音。例如：“hainei” => “海内存知己”。
  - 可用工具：Elasticsearch
- **模糊匹配：**中文系的同学们拼音一定是学得很好的，不会出现拼音拼错的情况。但我们也可以提供模糊匹配功能，即所输入的拼音与目标语句存在偏差的时候，仍能提供合理的候选语句。**Elasticsearch也有模糊匹配功能。**可能用上的模糊匹配算法：
  - **编辑距离（Levenshtein Distance）：**是用来衡量两个字符串之间差异的常用算法，即将一个字符串变为另一个字符串所需要的最少操作数（插入、删除、替换）。
    - 例如，用户输入“nihao”，实际想要输入的是“ninhao”，编辑距离为1，系统可以根据这一距离来推荐“您好”。
  - **模糊拼音映射表：**把常见的错误拼音或近音拼音映射到正确的拼音。
    - 例如，将“shi”和“si”归为同类，用户输入“si”的时候也可以联想到“是”。
  - **Trie树（前缀树）**
  - **n-gram 语言模型**
  - **BM25（Best Matching 25）**
  - **FST（有限状态自动机, Finite State Transducer）**
  - **深度学习模型（如Transformer）**

### 3. 用户接口（前端开发）

- 搭建网站：用户输入拼音，显示匹配的语句（简体和繁体）、引用出处、版本信息，提供复制按钮。
- 输入法插件：基于常用的开源输入法框架（如rime），实现输入法插件。
  - rime：https://github.com/rime
- 用户自定义语料库：用户可以导入自己的语料库（文本形式），从而个性化输入法所能联想到的古籍语句。

### 4. 论文撰写

## 近期目标（可以从零开始的工作）

- 调研主流输入法在输入古籍语句上的能力。
- 调研输入法常用的匹配算法（研究rime等的源代码）。
- 学习一下Elasticsearch的使用，主要是如何用它存储和检索数据。

- 收集古籍资料（不急）。
- 搭建网站框架（不急）。
- 学习如何把我们的扩展嵌入已有的输入法（可以从rime入手，不急）。
